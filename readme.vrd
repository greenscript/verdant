VRD1.0|TARGET:CLAUDE|MODE:EXTREME|CHUNKS:1/1
META:{files:1,tokens:3659,compressed:3.9%,generated:2025-06-06T16:02:35Z}
DICT:{FN=function,PARAM=parameter,AUTH=authentication,DB=database,API=application programming interface,CFG=configuration,DOC=documentation,IMPL=implementation,ENV=environment,REPO=repository}
---
F:README.md|D:2025-06-06T16:00:38Z|S:15224|L:226|T:go,perf,rust
H:Verdant v2.3,Features,New in v2.3,🆕 Previous Updates,v2.1,v2.0,Installation,Prerequisites,Quick Install,Manual Installation,Usage,Basic Usage,Advanced Examples,Options,Core Options,Chunking Options,AI Optimization,Override Defaults (Advanced),Output Formats,VRD Format (AI-Native) - RECOMMENDED ⭐,Markdown Format (Standard),Compression Levels,Model-Specific Optimizations,Example Output,VRD Format (AI-Native),Standard Markdown Format,How It Works,Advanced VRD Format,Standard Processing Pipeline,Smart Organization,Core Compression,Advanced Compression,Intelligent Chunking,Use Cases,Example Compression Results,VRD Format Performance ⭐,Standard Markdown Results,Format Comparison,Perfect For,Why Verdant?,Smart Defaults Philosophy,Contributing,License,Acknowledgments,Version History
C:TARGET:CLAUDE
NOTE:Structured data with Tech notation
---
F:README.md
Advanced Markdown Compression for AI Consumption
Verdant is specialized tool→compresses markdown files into dense, AI-readable format while preserving all key content. Perfect for fitting large DOC sets into AI context windows with intelligent chunking, model-specific Opt, and new VRD (AI-native) format.
- 🆕 VRD Format: New AI-native format with 17% fewer chunks and improved compression
- AI-Optimized Compression: Reduces token usage while maintaining readability
- Intelligent Chunking: Split large docs into digestible AI-friendly chunks with navigation
- Model-Specific Opt: Tailored compression for Claude, GPT, and GitHub Copilot
- Dual Format Support: Standard Markdown and VRD (AI-native) output formats
- Chronological Organization: Files automatically sorted by modification date for logical context flow
- Token Opt: Emoji removal and content streamlining for maximum efficiency
- Markdown-Aware: Understands document structure and formatting
- Duplicate Detection: Removes redundant content across multiple files
- Progressive Compression: Four levels (low, medium, high, extreme) for different needs
- Detailed Statistics: Track compression ratios and token savings
- Batch Processing: Combine multiple .md files with intelligent organization
-  VRD Format: New AI-native format→achieves 17% fewer chunks than standard Markdown
-  Superior AI Consumption: VRD format optimized specifically for AI processing with compressed syntax
-  Enhanced Compression: 71.9% of original size while maintaining full readability
-  Better Information Density: ~63KB per chunk vs ~54KB for MD format (17% fix)
-  Smart Navigation: Clear chunk boundaries with NEXT: pointers for seamless AI navigation
-  Rich Metadata: File info, modification dates, tags, and compression stats in headers
-  Smart File Ordering: Chronological sorting by default creates logical progression (oldest → newest)
-  Token Efficiency: Automatic emoji removal saves tokens for actual content
-  Better AI Context: Files ordered by modification time help AI understand project evolution
-  Optimized Defaults: Best practices enabled by default, advanced users can override
-  Smart Chunking: Automatically splits large outputs with navigation links
-  Model Targeting: Optimized compression for specific AI models
-  Extreme Mode: Ultra-aggressive compression with AI-optimized abbreviations
-  Enhanced Analytics: Detailed statistics and token estimation
-  Context Awareness: Maintains document relationships across chunks
- [Rust](https://rustup.rs/) (latest stable version)
1. Clone repo:
 CODE(bash): git clone https://github.com/yourusername/verdant.git| cd verdant
2. Run install script:
 CODE(bash): chmod +x install.sh| ./install.sh
3. Add to PATH (if not already done):
 CODE(bash): echo 'export PATH="$HOME/.local/bin:$PATH"' >> ~/.zshrc| source ~/.zshrc
CODE(bash):# Build optimized binary|cargo build --release|# Copy to directory in your PATH|cp target/release/verdant ~/.local/bin/|# Or install system-wide (requires sudo)|sudo cp target/release/verdant /usr/local/bin/
CODE(bash):# Use VRD format for maximum AI Opt (RECOMMENDED)|verdant --input ./docs --output compressed --format vrd --chunk|# Standard markdown format (classic)|verdant --input ./docs --output compressed --format md --chunk|# Compare formats side-by-side|verdant --input ./docs --output vrd_test --format vrd --chunk --stats|verdant --input ./docs --output md_test --format md --chunk --stats|# Extreme compression with VRD format for largest docs|verdant --input ./docs --output ultra_compressed --format vrd --level extreme --chunk
CODE(bash):# VRD format optimized for Claude with detailed analytics|verdant -i ./guides -o claude_guide --format vrd --model claude --chunk --stats|# GitHub Copilot Opt with VRD format|verdant -i ./api-docs -o copilot --format vrd --model copilot --chunk --max-lines 600|# Maximum compression demonstration (VRD vs MD comparison)|verdant -i ./large-docs -o vrd_demo --format vrd --level extreme --chunk --stats|verdant -i ./large-docs -o md_demo --format md --level extreme --chunk --stats
- `--input, -i`: Input directory containing .md files (required)
- `--output, -o`: Output file path/prefix (default: `compressed`)
- `--format, -f`: Output format - `vrd` (AI-native), `md` (standard) (default: `vrd`)
- `--level, -l`: Compression level - `low`, `medium`, `high`, `extreme` (default: `medium`)
- `--stats, -s`: Show detailed compression statistics
- `--chunk`: Enable chunking (splits large outputs into smaller files) (recommended)
- `--max-lines`: Maximum lines per chunk chunking→enabled (default: `800`)
- `--model`: Target AI model - `claude`, `gpt`, `copilot` (default: `claude`)
- `--ai-mode`: Enable AI-optimized extreme compression
- `--chronological`: Sort files by modification date (default: enabled)
- `--no-emojis`: Remove emojis to save tokens (default: enabled)
- `--no-chronological`: Disable chronological sorting
- `--emojis`: Keep emojis in output
- 17% fewer chunks than standard Markdown
- Better compression: 42.2% reduction (57.8% of original size)
- AI-optimized syntax: `→` for "that", `FN` for "FN"
- Rich metadata headers: File info, dates, tags, compression stats
- Smart navigation: Clear chunk boundaries with NEXT: pointers
- Information density: ~63KB per chunk vs ~54KB for MD
- Classic compatibility: Standard markdown output
- Universal support: Works with any markdown processor
- Familiar syntax: Standard markdown conventions
- Larger output: More chunks needed for same content
- Low: Basic whitespace removal and header compression
- Medium: + Code block compression, list Opt, fluff word removal, duplicate detection
- High: + Aggressive sentence compression and redundant phrase removal
- Extreme: + Article removal, abbreviations, mathematical notation (best with VRD format)
- Claude: Structured data with Tech notation, complex nested information
- GPT: Consistent formatting with explicit context markers, discrete chunks
- Copilot: Code-focused compression, file-type hints, smaller context windows
CODE: verdant v2.3| Compressing markdown for AI consumption| Target: claude | Level: extreme | Format: VRD | Chunking: enabled|Input: ./docs (22 files)|Output: compressed_.vrd|VRD1.0|TARGET:CLAUDE|MODE:EXTREME|CHUNKS:1/9|NEXT:compressed_2.vrd|META:{files:22,tokens:78714,compressed:6.5%,Gen:2025-06-06T14:15:29Z}|DICT:{FN=FN,API=app programming interface,AUTH=AUTH...}| COMPRESSION RESULTS:| Created 5 VRD chunks| 109,447 tokens → 78,720 tokens (28.1% reduction)| 314,880 bytes total (17% fewer chunks than MD format)
CODE: verdant v2.3| Target: claude | Level: medium | Format: MD | Chunking: enabled|Input: ./docs|Output: compressed_chunk_.md|Found 20 markdown files:| Files sorted chronologically (oldest → newest)| ./docs/ARCHITECTURE.md| ./docs/API_DESIGN.md| ./docs/RECENT_FEATURES.md| COMPRESSION RESULTS:| Created 6 MD chunks| 9807 lines → 4572 lines (53.4% reduction)| 324,744 bytes total
Verdant's VRD (AI-native) format employs specialized compression techniques:
1. Smart Header Metadata: Rich file information, modification dates, and compression stats
2. Dictionary Compression: Common terms abbreviated (FN=FN, API=app programming interface)
3. Arrow Notation: Semantic shortcuts (`→` for "that", "to", "then")
4. Structured Markers: Clear content separation (F:filename, H:headers, C:content, X:code)
5. Optimized Chunking: Maintains semantic continuity across fewer chunks
Verdant applies multiple compression strategies in this order:
1. Chronological Sorting: Orders files by modification date for logical progression
2. Token Opt: Removes emojis and unnecessary visual elements
3. Whitespace Opt: Removes excessive spacing and empty lines
4. Header Compression: `# Title` → `H1:Title` (MD) or `H:Title` (VRD)
5. Code Block Compression: Condenses code while preserving work
6. List Opt: Streamlines bullet points and numbered lists
7. Duplicate Detection: Removes identical paragraphs across files
8. Fluff Removal: Eliminates verbose phrases and connectors
9. Sentence Compression: Removes redundant words and phrases
10. AI Abbreviations: Common terms → concise notation (FN → FN)
11. Mathematical Notation: "→" → "→", "" → "∴"
12. Smart Splitting: Breaks documents at logical boundaries
13. Navigation Links: Each chunk links to next for continuity
14. Context Preservation: Maintains document relationships
15. Metadata Tracking: Lines, tokens, and content estimates per chunk
- AI Context Opt: Fit more DOC into ChatGPT/Claude prompts
- Daily Dev: Quick context preparation for AI pair programming
- Large Codebase Analysis: Compress extensive DOC for AI code reviews
- Knowledge Base Compression: Condense large wikis for AI consumption
- Doc Analysis: Prepare docs for AI-powered analysis
- Context Window Management: Maximize information density for LLMs
- Model-Specific Preparation: Optimize content for different AI models
Actual results on large DOC sets (22 files, 437KB):
- Character compression: 42.2% reduction (252KB final size)
- Line compression: 65.9% reduction (9,807 → 3,345 lines)
- Duplicate removal: 1,720 duplicate paragraphs eliminated
- Token efficiency: ~1,000 tokens saved via emoji removal alone
- File Opt: Chronological ordering improves AI context understanding
Traditional markdown compression on same dataset:
- Character compression: 25.9% reduction (324KB final size)
- Line compression: 53.6% reduction (9,807 → 4,554 lines)
- VRD advantage: 16.3% better compression than standard markdown
- File size difference: VRD produces 71KB smaller output (22% less data)
- Readability: Fully preserved for AI consumption
| Metric | VRD Format | Markdown Format | VRD Advantage |
|--------|------------|-----------------|---------------|
| Character Compression | 42.2% reduction | 25.9% reduction | 16.3% better |
| Line Compression | 65.9% reduction | 53.6% reduction | 12.3% better |
| Final File Size | 252KB | 324KB | 22% smaller |
| Duplicate Removal | 1,720 paragraphs | 1,720 paragraphs | Same efficiency |
| Token Savings | ~1,000+ tokens | ~1,000+ tokens | Plus format efficiency |
| AI Processing | Optimized syntax | Standard syntax | Better comprehension |
- Doc Teams: Preparing large docs for AI analysis with logical flow
- Tech Writing: Optimizing content for AI-powered tools
- Code Reviews: Condensing project DOC for AI assistance
- Knowledge Management: Making large wikis AI-accessible
- Project Handoffs: Creating chronologically organized context for new team members
The Problem: Modern DOC sets are too large for AI context windows, causing:
- Truncated responses
- Lost context
- AI models getting overwhelmed
- Slow processing times
- Poor understanding of project evolution
The Solution: Verdant effectively compresses and organizes DOC while:
- Improved VRD Format: 17% fewer chunks with enhanced AI consumption
- Preserving all key information
- Maintaining logical chronological structure
- Adding navigation between chunks
- Optimizing for specific AI models
- Removing token waste (emojis, redundancy)
- Providing detailed analytics
The VRD Advantage: Our AI-native format provides:
- Better Compression: 28.1% size reduction vs 25.8% for standard markdown
- Better Navigation: Fewer chunks mean faster AI processing
- Rich Metadata: Smart headers with file info, dates, and compression stats
- Semantic Opt: Abbreviations and symbols designed for AI understanding
Verdant v2.3 embraces "AI-first" design:
- VRD format by default for maximum AI Opt
- Chunking enabled for better context management
- Chronological ordering helps AI understand project progression
- Emoji removal maximizes content density
- Medium compression balances efficiency with safety
- Claude targeting works well for most AI models
- Advanced users can override any default with flags
Pro Tip: Start with `verdant -i ./docs -o output --format vrd --chunk --stats` for best AI experience!
1. Fork repo
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request
This project is licensed under MIT License - see [LICENSE](LICENSE) file for details.
- Built with [Rust](https://www.rust-lang.org/) for maximum Perf
- CLI powered by [clap](https://github.com/clap-rs/clap) for excellent UX
- Regex processing via [regex](https://github.com/rust-lang/regex) for reliable text processing
- File traversal with [walkdir](https://github.com/BurntSushi/walkdir) for efficient directory handling
---
Made with for AI-powered developer community
"∵ your DOC shouldn't fight your AI assistant"
Note: VRD format is optimized for multi-file DOC sets. For single files:
- VRD: ~20% compression with format overhead
- MD: ~3-5% compression with minimal overhead
- Recommendation: Use standard markdown (`--format md`) for single files
- v2.3.1: Enhanced VRD optimizations (checkbox compression, emphasis Opt), achieving 42.2% compression
- v2.3: VRD format introduction, multi-file Opt, AI-native compression
- v2.3: VRD format, 17% fewer chunks, improved AI-native compression
- v2.1: Smart defaults (chronological ordering, emoji removal), enhanced UX
- v2.0: Chunking, model-specific Opt, extreme compression modes
- v1.0: Core compression engine, duplicate detection, basic statistics
|
|
