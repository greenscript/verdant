VRD1.0|TARGET:CLAUDE|MODE:EXTREME|CHUNKS:1/1
META:{files:1,tokens:3245,compressed:16.4%,generated:2025-06-06T16:20:50Z}
DICT:{FN=function,PARAM=parameter,AUTH=authentication,DB=database,API=application programming interface,CFG=configuration,DOC=documentation,IMPL=implementation,ENV=environment,REPO=repository}
---
F:README.md|D:2025-06-06T16:20:32Z|S:15526|L:357|T:go,perf,rust
H: Verdant v2.3.1,Features,New in v2.3.1,üÜï Previous Updates,v2.3,v2.1,v2.0,Installation,Prerequisites,Quick Install,Manual Installation,Build optimized binary,Copy to directory in your PATH,Or install system-wide (requires sudo),Usage,Basic Usage,Use VRD format for maximum AI optimization (RECOMMENDED),Standard markdown format (classic),Compare formats side-by-side,Extreme compression with VRD format for largest docs,Advanced Examples,VRD format optimized for Claude with detailed analytics,GitHub Copilot optimization with VRD format,Maximum compression demonstration (VRD vs MD comparison),Options,Core Options,Chunking Options,AI Optimization,Override Defaults (Advanced),Output Formats,VRD Format (AI-Native) - RECOMMENDED ‚≠ê,Markdown Format (Standard),Compression Levels,Model-Specific Optimizations,Example Output,VRD Format (AI-Native),Standard Markdown Format,How It Works,Advanced VRD Format,Standard Processing Pipeline,Smart Organization,Core Compression,Advanced Compression,Intelligent Chunking,Use Cases,Example Compression Results,VRD Format Performance ‚≠ê,Standard Markdown Results,Format Comparison,Perfect For,Why Verdant?,Smart Defaults Philosophy,Contributing,License,Acknowledgments,Version History
C:Advanced Markdown Compression for AI Consumption
Verdant is specialized tool‚Üícompresses markdown files into dense, AI-readable format while preserving all key content. Perfect for fitting large DOC sets into AI context windows with intelligent chunking, model-specific Opt, and new VRD (AI-native) format.
- üÜï VRD Format: New AI-native format with superior compression and improved AI consumption
- AI-Optimized Compression: Reduces token usage while maintaining readability
- Intelligent Chunking: Split large docs into digestible AI-friendly chunks with navigation
- Model-Specific Opt: Tailored compression for Claude, GPT, and GitHub Copilot
- Dual Format Support: Standard Markdown and VRD (AI-native) output formats
- Chronological Organization: Files automatically sorted by modification date for logical context flow
- Token Opt: Emoji removal and content streamlining for maximum efficiency
- Markdown-Aware: Understands document structure and formatting
- Duplicate Detection: Removes redundant content across multiple files
- Progressive Compression: Four levels (low, medium, high, extreme) for different needs
- Detailed Statistics: Track compression ratios and token savings
- Batch Processing: Combine multiple .md files with intelligent organization
-  Enhanced VRD Optimizations: Checkbox compression (``/``), emphasis Opt, achieving 42.2% compression
-  Improved Perf: Superior multi-file compression with up to 1,720 duplicate paragraphs removed
-  Token Efficiency: ~1,000+ tokens saved via emoji removal and format optimizations
-  Smart Recommendations: Clear guidance on to‚Üíuse VRD vs standard markdown formats
-  VRD Format: New AI-native format optimized specifically for AI processing
-  Superior AI Consumption: Enhanced compression with rich metadata and smart navigation
-  Better Information Density: Optimized syntax with arrow notation and abbreviations
-  Smart Navigation: Clear chunk boundaries with NEXT: pointers for seamless AI navigation
-  Rich Metadata: File info, modification dates, tags, and compression stats in headers
-  Smart File Ordering: Chronological sorting by default creates logical progression (oldest ‚Üí newest)
-  Token Efficiency: Automatic emoji removal saves tokens for actual content
-  Better AI Context: Files ordered by modification time help AI understand project evolution
- Ô∏è Optimized Defaults: Best practices enabled by default, advanced users can override
-  Smart Chunking: Automatically splits large outputs with navigation links
-  Model Targeting: Optimized compression for specific AI models
-  Extreme Mode: Ultra-aggressive compression with AI-optimized abbreviations
-  Enhanced Analytics: Detailed statistics and token estimation
-  Context Awareness: Maintains document relationships across chunks
- [Rust](https://rustup.rs/) (latest stable version)
1. Clone repo:
2. Run install script:
3. Add to PATH (if not already done):
- `--input, -i`: Input directory containing .md files (required)
- `--output, -o`: Output file path/prefix (default: `compressed`)
- `--format, -f`: Output format - `vrd` (AI-native), `md` (standard) (default: `vrd`)
- `--level, -l`: Compression level - `low`, `medium`, `high`, `extreme` (default: `medium`)
- `--stats, -s`: Show detailed compression statistics
- `--chunk`: Enable chunking (splits large outputs into smaller files) (recommended)
- `--max-lines`: Maximum lines per chunk chunking‚Üíenabled (default: `800`)
- `--model`: Target AI model - `claude`, `gpt`, `copilot` (default: `claude`)
- `--ai-mode`: Enable AI-optimized extreme compression
- `--chronological`: Sort files by modification date (default: enabled)
- `--no-emojis`: Remove emojis to save tokens (default: enabled)
- `--no-chronological`: Disable chronological sorting
- `--emojis`: Keep emojis in output
- Superior multi-file compression: 42.2% reduction (57.8% of original size)
- AI-optimized syntax: `‚Üí` for relationships, `FN` for functions, ``/`` for checkboxes, etc.
- Rich metadata headers: File info, dates, tags, compression stats
- Smart navigation: Clear chunk boundaries with NEXT: pointers
- Duplicate detection: Removes up to 1,700+ duplicate paragraphs across files
- Token Opt: Automatic emoji removal (500+ emojis = ~1,000 tokens saved)
- Classic compatibility: Standard markdown output
- Universal support: Works with any markdown processor
- Familiar syntax: Standard markdown conventions
- Larger output: More chunks needed for same content
Note: VRD format is optimized for multi-file DOC sets. For single files:
- VRD: ~20% compression with format overhead
- MD: ~3-5% compression with minimal overhead
- Recommendation: Use standard markdown (`--format md`) for single files
- Low: Basic whitespace removal and header compression
- Medium: + Code block compression, list Opt, fluff word removal, duplicate detection
- High: + Aggressive sentence compression and redundant phrase removal
- Extreme: + Article removal, abbreviations, mathematical notation (best with VRD format)
- Claude: Structured data with Tech notation, complex nested information
- GPT: Consistent formatting with explicit context markers, discrete chunks
- Copilot: Code-focused compression, file-type hints, smaller context windows
Verdant's VRD (AI-native) format employs specialized compression techniques:
1. Smart Header Metadata: Rich file information, modification dates, and compression stats
2. Dictionary Compression: Common terms abbreviated (FN=FN, API=app programming interface)
3. Arrow Notation: Semantic shortcuts (`‚Üí` for relationships, ``/`` for checkboxes)
4. Structured Markers: Clear content separation (F:filename, H:headers, C:content, X:code)
5. Optimized Chunking: Maintains semantic continuity across fewer chunks
Verdant applies multiple compression strategies in this order:
1. Chronological Sorting: Orders files by modification date for logical progression
2. Token Opt: Removes emojis and unnecessary visual elements
3. Whitespace Opt: Removes excessive spacing and empty lines
4. Header Compression: `# Title` ‚Üí `H1:Title` (MD) or `H:Title` (VRD)
5. Code Block Compression: Condenses code while preserving work
6. List Opt: Streamlines bullet points and numbered lists
7. Duplicate Detection: Removes identical paragraphs across files
8. Fluff Removal: Eliminates verbose phrases and connectors
9. Sentence Compression: Removes redundant words and phrases
10. AI Abbreviations: Common terms ‚Üí concise notation (FN ‚Üí FN)
11. Mathematical Notation: "returns" ‚Üí "‚Üí", "‚à¥" ‚Üí "‚à¥"
12. Smart Splitting: Breaks documents at logical boundaries
13. Navigation Links: Each chunk links to next for continuity
14. Context Preservation: Maintains document relationships
15. Metadata Tracking: Lines, tokens, and content estimates per chunk
- AI Context Opt: Fit more DOC into ChatGPT/Claude prompts
- Daily Dev: Quick context preparation for AI pair programming
- Large Codebase Analysis: Compress extensive DOC for AI code reviews
- Knowledge Base Compression: Condense large wikis for AI consumption
- Doc Analysis: Prepare docs for AI-powered analysis
- Context Window Management: Maximize information density for LLMs
- Model-Specific Preparation: Optimize content for different AI models
Actual results on large DOC sets (22 files, 437KB):
- Character compression: 42.2% reduction (252KB final size)
- Line compression: 65.9% reduction (9,807 ‚Üí 3,345 lines)
- Duplicate removal: 1,720 duplicate paragraphs eliminated
- Token efficiency: ~1,000 tokens saved via emoji removal alone
- File Opt: Chronological ordering improves AI context understanding
Traditional markdown compression on same dataset:
- Character compression: 25.9% reduction (324KB final size)
- Line compression: 53.6% reduction (9,807 ‚Üí 4,554 lines)
- VRD advantage: 16.3% better compression than standard markdown
- File size difference: VRD produces 71KB smaller output (22% less data)
- Readability: Fully preserved for AI consumption
| Metric | VRD Format | Markdown Format | VRD Advantage |
|--------|------------|-----------------|---------------|
| Character Compression | 42.2% reduction | 25.9% reduction | 16.3% better |
| Line Compression | 65.9% reduction | 53.6% reduction | 12.3% better |
| Final File Size | 252KB | 324KB | 22% smaller |
| Duplicate Removal | 1,720 paragraphs | 1,720 paragraphs | Same efficiency |
| Token Savings | ~1,000+ tokens | ~1,000+ tokens | Plus format efficiency |
| AI Processing | Optimized syntax | Standard syntax | Better comprehension |
- Doc Teams: Preparing large docs for AI analysis with logical flow
- Tech Writing: Optimizing content for AI-powered tools
- Code Reviews: Condensing project DOC for AI assistance
- Knowledge Management: Making large wikis AI-accessible
- Project Handoffs: Creating chronologically organized context for new team members
The Problem: Modern DOC sets are too large for AI context windows, causing:
- Truncated responses
- Lost context
- AI models getting overwhelmed
- Slow processing times
- Poor understanding of project evolution
The Solution: Verdant effectively compresses and organizes DOC while:
- Superior VRD Format: 42.2% compression with enhanced AI consumption
- Preserving all key information
- Maintaining logical chronological structure
- Adding navigation between chunks
- Optimizing for specific AI models
- Removing token waste (emojis, redundancy)
- Providing detailed analytics
The VRD Advantage: Our AI-native format provides:
- Better Compression: 42.2% size reduction vs 25.9% for standard markdown
- Better Navigation: Fewer operations mean faster AI processing
- Rich Metadata: Smart headers with file info, dates, and compression stats
- Semantic Opt: Abbreviations and symbols designed for AI understanding
Verdant v2.3.1 embraces "AI-first" design:
- VRD format by default for maximum AI Opt
- Chunking enabled for better context management
- Chronological ordering helps AI understand project progression
- Emoji removal maximizes content density
- Medium compression balances efficiency with safety
- Claude targeting works well for most AI models
- Advanced users can override any default with flags
Pro Tip: Start with `verdant -i ./docs -o output --format vrd --chunk --stats` for best AI experience!
1. Fork repo
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request
This project is licensed under MIT License - see [LICENSE](LICENSE) file for details.
- Built with [Rust](https://www.rust-lang.org/) for maximum Perf
- CLI powered by [clap](https://github.com/clap-rs/clap) for excellent UX
- Regex processing via [regex](https://github.com/rust-lang/regex) for reliable text processing
- File traversal with [walkdir](https://github.com/BurntSushi/walkdir) for efficient directory handling
---
Made with for AI-powered developer community
"‚àµ your DOC shouldn't fight your AI assistant"
- v2.3.1: Enhanced VRD optimizations (checkbox compression, emphasis Opt), achieving 42.2% compression
- v2.3: VRD format introduction, multi-file Opt, AI-native compression
- v2.1: Smart defaults (chronological ordering, emoji removal), enhanced UX
- v2.0: Chunking, model-specific Opt, extreme compression modes
- v1.0: Core compression engine, duplicate detection, basic statistics
|
